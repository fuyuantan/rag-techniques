This code aims to evaluate our RAG using metrics such as **hit rate, precision, recall, and golden answer keywords**. <br>

We define golden ground truth data (json) in `evaluate_retrieval.py`.

You only need to config your **HuggingFace Token** in `3-RAG-Eval.py`, then can run it smoothly.

File Intro:<br>
`test-pdf2.pdf` is the splitted and retrieved PDF. Also you can use your own PDF file.<br>

Running Output:
![微信截图_20250521210348](https://github.com/user-attachments/assets/10da4f81-7990-43bd-b8d5-014e9c69cd5b)

